{"ast":null,"code":"// src/services/aiService.js\nlet documentContext=[];export const setDocumentContext=context=>{documentContext=context;console.log(\"Document context updated:\",documentContext.length,\"chunks\");};export const testGeminiAPIConnection=async()=>{try{const API_KEY=process.env.REACT_APP_GEMINI_API_KEY;if(!API_KEY){return{success:false,message:\"API key not configured\"};}// Use the correct endpoint with the latest model name\nconst testEndpoint=\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\";const testMessage=\"Hello, this is a test message.\";const response=await fetch(`${testEndpoint}?key=${API_KEY}`,{method:\"POST\",headers:{\"Content-Type\":\"application/json\"},body:JSON.stringify({contents:[{parts:[{text:testMessage}]}]})});const statusCode=response.status;let responseText=\"\";try{const responseData=await response.json();responseText=JSON.stringify(responseData,null,2);}catch(e){responseText=await response.text();}return{success:response.ok,statusCode,responseText,message:response.ok?\"API connection successful\":`API error: ${statusCode}`};}catch(error){return{success:false,message:`Connection error: ${error.message}`,error};}};export const queryGeminiAI=async message=>{try{const API_KEY=process.env.REACT_APP_GEMINI_API_KEY;if(!API_KEY){console.error(\"Missing Gemini API key. Set REACT_APP_GEMINI_API_KEY in your environment.\");throw new Error(\"API key not configured\");}console.log(\"Using API key starting with:\",API_KEY.substring(0,3)+\"...\"+API_KEY.slice(-3));// Prepare the full prompt\nlet fullPrompt=\"You are an AI assistant specializing in last mile logistics in India. \";fullPrompt+=\"Provide detailed, accurate information about delivery services, tracking, shipping costs, and logistics coverage areas in India. \";fullPrompt+=\"Be helpful, concise, and focus on Indian logistics context.\\n\\n\";fullPrompt+=\"User question: \"+message;// Add document context if available\nif(documentContext&&documentContext.length>0){fullPrompt+=\"\\n\\nReference these document sections when applicable:\\n\";const relevantChunks=documentContext.slice(0,3);relevantChunks.forEach((chunk,i)=>{fullPrompt+=`\\nSection ${i+1}: ${chunk}\\n`;});fullPrompt+=\"\\nPlease use this document information when relevant to answer the user's question.\";}// Use the correct endpoint and model name\n// Try gemini-1.5-flash first (current model)\nconst apiUrl=\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\";// Format the request \nconst requestBody={contents:[{parts:[{text:fullPrompt}]}],generationConfig:{temperature:0.7,maxOutputTokens:800}};console.log(\"Sending request to Gemini API at:\",apiUrl);// Send the request\nconst response=await fetch(`${apiUrl}?key=${API_KEY}`,{method:\"POST\",headers:{\"Content-Type\":\"application/json\"},body:JSON.stringify(requestBody)});console.log(\"API Response status:\",response.status);if(!response.ok){const errorText=await response.text();console.error(\"API Error:\",response.status,errorText);if(response.status===404){// Try fallback to gemini-1.0-pro if 1.5-flash isn't found\nconsole.log(\"Model not found, trying fallback to gemini-1.0-pro\");return await queryWithFallbackModel(fullPrompt,API_KEY);}else if(response.status===403){throw new Error(\"API access forbidden. Check if API key has correct permissions.\");}else if(response.status===429){throw new Error(\"Rate limit exceeded. Please try again later.\");}else{throw new Error(`API error: ${response.status} ${errorText}`);}}const data=await response.json();// Extract text from the response\nlet text=\"\";if(data.candidates&&data.candidates.length>0&&data.candidates[0].content&&data.candidates[0].content.parts){text=data.candidates[0].content.parts.map(part=>part.text||\"\").join(\"\");console.log(\"Successfully extracted text, length:\",text.length);}else{console.warn(\"Unexpected API response structure:\",JSON.stringify(data,null,2));throw new Error(\"Unexpected API response structure\");}return text;}catch(error){console.error(\"Error in Gemini API call:\",error);throw error;}};// Fallback function to try different models\nasync function queryWithFallbackModel(prompt,apiKey){// Try a sequence of models until one works\nconst models=[\"gemini-1.0-pro\",\"gemini-pro\",\"gemini-pro-latest\"];let lastError=null;for(const model of models){try{console.log(`Trying model: ${model}`);const fallbackUrl=`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`;const requestBody={contents:[{parts:[{text:prompt}]}],generationConfig:{temperature:0.7,maxOutputTokens:800}};const response=await fetch(`${fallbackUrl}?key=${apiKey}`,{method:\"POST\",headers:{\"Content-Type\":\"application/json\"},body:JSON.stringify(requestBody)});if(!response.ok){const errorText=await response.text();console.log(`Model ${model} failed with status:`,response.status,errorText);lastError=new Error(`API error with ${model}: ${response.status}`);continue;// Try next model\n}const data=await response.json();if(data.candidates&&data.candidates.length>0&&data.candidates[0].content&&data.candidates[0].content.parts){const text=data.candidates[0].content.parts.map(part=>part.text||\"\").join(\"\");console.log(`Successfully used fallback model: ${model}`);return text;}else{console.warn(`Unexpected response from ${model}:`,JSON.stringify(data,null,2));lastError=new Error(`Unexpected response structure from ${model}`);continue;// Try next model\n}}catch(error){console.error(`Error with model ${model}:`,error);lastError=error;// Continue to the next model\n}}// If we get here, all models failed\nthrow lastError||new Error(\"All fallback models failed\");}","map":{"version":3,"names":["documentContext","setDocumentContext","context","console","log","length","testGeminiAPIConnection","API_KEY","process","env","REACT_APP_GEMINI_API_KEY","success","message","testEndpoint","testMessage","response","fetch","method","headers","body","JSON","stringify","contents","parts","text","statusCode","status","responseText","responseData","json","e","ok","error","queryGeminiAI","Error","substring","slice","fullPrompt","relevantChunks","forEach","chunk","i","apiUrl","requestBody","generationConfig","temperature","maxOutputTokens","errorText","queryWithFallbackModel","data","candidates","content","map","part","join","warn","prompt","apiKey","models","lastError","model","fallbackUrl"],"sources":["/Users/madhusudhan/Documents/GitHub/LMPandaSensei/src/services/aiService.js"],"sourcesContent":["// src/services/aiService.js\nlet documentContext = [];\n\nexport const setDocumentContext = (context) => {\n  documentContext = context;\n  console.log(\"Document context updated:\", documentContext.length, \"chunks\");\n};\n\nexport const testGeminiAPIConnection = async () => {\n  try {\n    const API_KEY = process.env.REACT_APP_GEMINI_API_KEY;\n    \n    if (!API_KEY) {\n      return { success: false, message: \"API key not configured\" };\n    }\n    \n    // Use the correct endpoint with the latest model name\n    const testEndpoint = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\";\n    const testMessage = \"Hello, this is a test message.\";\n    \n    const response = await fetch(\n      `${testEndpoint}?key=${API_KEY}`,\n      {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n          contents: [{ parts: [{ text: testMessage }] }]\n        })\n      }\n    );\n    \n    const statusCode = response.status;\n    let responseText = \"\";\n    \n    try {\n      const responseData = await response.json();\n      responseText = JSON.stringify(responseData, null, 2);\n    } catch (e) {\n      responseText = await response.text();\n    }\n    \n    return {\n      success: response.ok,\n      statusCode,\n      responseText,\n      message: response.ok ? \"API connection successful\" : `API error: ${statusCode}`\n    };\n  } catch (error) {\n    return {\n      success: false,\n      message: `Connection error: ${error.message}`,\n      error\n    };\n  }\n};\n\nexport const queryGeminiAI = async (message) => {\n  try {\n    const API_KEY = process.env.REACT_APP_GEMINI_API_KEY;\n    \n    if (!API_KEY) {\n      console.error(\"Missing Gemini API key. Set REACT_APP_GEMINI_API_KEY in your environment.\");\n      throw new Error(\"API key not configured\");\n    }\n\n    console.log(\"Using API key starting with:\", API_KEY.substring(0, 3) + \"...\" + API_KEY.slice(-3));\n\n    // Prepare the full prompt\n    let fullPrompt = \"You are an AI assistant specializing in last mile logistics in India. \";\n    fullPrompt += \"Provide detailed, accurate information about delivery services, tracking, shipping costs, and logistics coverage areas in India. \";\n    fullPrompt += \"Be helpful, concise, and focus on Indian logistics context.\\n\\n\";\n    fullPrompt += \"User question: \" + message;\n    \n    // Add document context if available\n    if (documentContext && documentContext.length > 0) {\n      fullPrompt += \"\\n\\nReference these document sections when applicable:\\n\";\n      const relevantChunks = documentContext.slice(0, 3);\n      relevantChunks.forEach((chunk, i) => {\n        fullPrompt += `\\nSection ${i+1}: ${chunk}\\n`;\n      });\n      fullPrompt += \"\\nPlease use this document information when relevant to answer the user's question.\";\n    }\n\n    // Use the correct endpoint and model name\n    // Try gemini-1.5-flash first (current model)\n    const apiUrl = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\";\n    \n    // Format the request \n    const requestBody = {\n      contents: [\n        {\n          parts: [\n            { text: fullPrompt }\n          ]\n        }\n      ],\n      generationConfig: {\n        temperature: 0.7,\n        maxOutputTokens: 800\n      }\n    };\n    \n    console.log(\"Sending request to Gemini API at:\", apiUrl);\n    \n    // Send the request\n    const response = await fetch(\n      `${apiUrl}?key=${API_KEY}`,\n      {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify(requestBody)\n      }\n    );\n\n    console.log(\"API Response status:\", response.status);\n    \n    if (!response.ok) {\n      const errorText = await response.text();\n      console.error(\"API Error:\", response.status, errorText);\n      \n      if (response.status === 404) {\n        // Try fallback to gemini-1.0-pro if 1.5-flash isn't found\n        console.log(\"Model not found, trying fallback to gemini-1.0-pro\");\n        return await queryWithFallbackModel(fullPrompt, API_KEY);\n      } else if (response.status === 403) {\n        throw new Error(\"API access forbidden. Check if API key has correct permissions.\");\n      } else if (response.status === 429) {\n        throw new Error(\"Rate limit exceeded. Please try again later.\");\n      } else {\n        throw new Error(`API error: ${response.status} ${errorText}`);\n      }\n    }\n\n    const data = await response.json();\n    \n    // Extract text from the response\n    let text = \"\";\n    if (data.candidates && \n        data.candidates.length > 0 && \n        data.candidates[0].content && \n        data.candidates[0].content.parts) {\n      text = data.candidates[0].content.parts\n        .map(part => part.text || \"\")\n        .join(\"\");\n      console.log(\"Successfully extracted text, length:\", text.length);\n    } else {\n      console.warn(\"Unexpected API response structure:\", JSON.stringify(data, null, 2));\n      throw new Error(\"Unexpected API response structure\");\n    }\n    \n    return text;\n  } catch (error) {\n    console.error(\"Error in Gemini API call:\", error);\n    throw error;\n  }\n};\n\n// Fallback function to try different models\nasync function queryWithFallbackModel(prompt, apiKey) {\n  // Try a sequence of models until one works\n  const models = [\n    \"gemini-1.0-pro\",\n    \"gemini-pro\",\n    \"gemini-pro-latest\"\n  ];\n  \n  let lastError = null;\n  \n  for (const model of models) {\n    try {\n      console.log(`Trying model: ${model}`);\n      const fallbackUrl = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`;\n      \n      const requestBody = {\n        contents: [\n          {\n            parts: [\n              { text: prompt }\n            ]\n          }\n        ],\n        generationConfig: {\n          temperature: 0.7,\n          maxOutputTokens: 800\n        }\n      };\n      \n      const response = await fetch(\n        `${fallbackUrl}?key=${apiKey}`,\n        {\n          method: \"POST\",\n          headers: {\n            \"Content-Type\": \"application/json\"\n          },\n          body: JSON.stringify(requestBody)\n        }\n      );\n      \n      if (!response.ok) {\n        const errorText = await response.text();\n        console.log(`Model ${model} failed with status:`, response.status, errorText);\n        lastError = new Error(`API error with ${model}: ${response.status}`);\n        continue; // Try next model\n      }\n      \n      const data = await response.json();\n      \n      if (data.candidates && \n          data.candidates.length > 0 && \n          data.candidates[0].content && \n          data.candidates[0].content.parts) {\n        const text = data.candidates[0].content.parts\n          .map(part => part.text || \"\")\n          .join(\"\");\n        console.log(`Successfully used fallback model: ${model}`);\n        return text;\n      } else {\n        console.warn(`Unexpected response from ${model}:`, JSON.stringify(data, null, 2));\n        lastError = new Error(`Unexpected response structure from ${model}`);\n        continue; // Try next model\n      }\n    } catch (error) {\n      console.error(`Error with model ${model}:`, error);\n      lastError = error;\n      // Continue to the next model\n    }\n  }\n  \n  // If we get here, all models failed\n  throw lastError || new Error(\"All fallback models failed\");\n}\n"],"mappings":"AAAA;AACA,GAAI,CAAAA,eAAe,CAAG,EAAE,CAExB,MAAO,MAAM,CAAAC,kBAAkB,CAAIC,OAAO,EAAK,CAC7CF,eAAe,CAAGE,OAAO,CACzBC,OAAO,CAACC,GAAG,CAAC,2BAA2B,CAAEJ,eAAe,CAACK,MAAM,CAAE,QAAQ,CAAC,CAC5E,CAAC,CAED,MAAO,MAAM,CAAAC,uBAAuB,CAAG,KAAAA,CAAA,GAAY,CACjD,GAAI,CACF,KAAM,CAAAC,OAAO,CAAGC,OAAO,CAACC,GAAG,CAACC,wBAAwB,CAEpD,GAAI,CAACH,OAAO,CAAE,CACZ,MAAO,CAAEI,OAAO,CAAE,KAAK,CAAEC,OAAO,CAAE,wBAAyB,CAAC,CAC9D,CAEA;AACA,KAAM,CAAAC,YAAY,CAAG,0FAA0F,CAC/G,KAAM,CAAAC,WAAW,CAAG,gCAAgC,CAEpD,KAAM,CAAAC,QAAQ,CAAG,KAAM,CAAAC,KAAK,CAC1B,GAAGH,YAAY,QAAQN,OAAO,EAAE,CAChC,CACEU,MAAM,CAAE,MAAM,CACdC,OAAO,CAAE,CACP,cAAc,CAAE,kBAClB,CAAC,CACDC,IAAI,CAAEC,IAAI,CAACC,SAAS,CAAC,CACnBC,QAAQ,CAAE,CAAC,CAAEC,KAAK,CAAE,CAAC,CAAEC,IAAI,CAAEV,WAAY,CAAC,CAAE,CAAC,CAC/C,CAAC,CACH,CACF,CAAC,CAED,KAAM,CAAAW,UAAU,CAAGV,QAAQ,CAACW,MAAM,CAClC,GAAI,CAAAC,YAAY,CAAG,EAAE,CAErB,GAAI,CACF,KAAM,CAAAC,YAAY,CAAG,KAAM,CAAAb,QAAQ,CAACc,IAAI,CAAC,CAAC,CAC1CF,YAAY,CAAGP,IAAI,CAACC,SAAS,CAACO,YAAY,CAAE,IAAI,CAAE,CAAC,CAAC,CACtD,CAAE,MAAOE,CAAC,CAAE,CACVH,YAAY,CAAG,KAAM,CAAAZ,QAAQ,CAACS,IAAI,CAAC,CAAC,CACtC,CAEA,MAAO,CACLb,OAAO,CAAEI,QAAQ,CAACgB,EAAE,CACpBN,UAAU,CACVE,YAAY,CACZf,OAAO,CAAEG,QAAQ,CAACgB,EAAE,CAAG,2BAA2B,CAAG,cAAcN,UAAU,EAC/E,CAAC,CACH,CAAE,MAAOO,KAAK,CAAE,CACd,MAAO,CACLrB,OAAO,CAAE,KAAK,CACdC,OAAO,CAAE,qBAAqBoB,KAAK,CAACpB,OAAO,EAAE,CAC7CoB,KACF,CAAC,CACH,CACF,CAAC,CAED,MAAO,MAAM,CAAAC,aAAa,CAAG,KAAO,CAAArB,OAAO,EAAK,CAC9C,GAAI,CACF,KAAM,CAAAL,OAAO,CAAGC,OAAO,CAACC,GAAG,CAACC,wBAAwB,CAEpD,GAAI,CAACH,OAAO,CAAE,CACZJ,OAAO,CAAC6B,KAAK,CAAC,2EAA2E,CAAC,CAC1F,KAAM,IAAI,CAAAE,KAAK,CAAC,wBAAwB,CAAC,CAC3C,CAEA/B,OAAO,CAACC,GAAG,CAAC,8BAA8B,CAAEG,OAAO,CAAC4B,SAAS,CAAC,CAAC,CAAE,CAAC,CAAC,CAAG,KAAK,CAAG5B,OAAO,CAAC6B,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAEhG;AACA,GAAI,CAAAC,UAAU,CAAG,wEAAwE,CACzFA,UAAU,EAAI,mIAAmI,CACjJA,UAAU,EAAI,iEAAiE,CAC/EA,UAAU,EAAI,iBAAiB,CAAGzB,OAAO,CAEzC;AACA,GAAIZ,eAAe,EAAIA,eAAe,CAACK,MAAM,CAAG,CAAC,CAAE,CACjDgC,UAAU,EAAI,0DAA0D,CACxE,KAAM,CAAAC,cAAc,CAAGtC,eAAe,CAACoC,KAAK,CAAC,CAAC,CAAE,CAAC,CAAC,CAClDE,cAAc,CAACC,OAAO,CAAC,CAACC,KAAK,CAAEC,CAAC,GAAK,CACnCJ,UAAU,EAAI,aAAaI,CAAC,CAAC,CAAC,KAAKD,KAAK,IAAI,CAC9C,CAAC,CAAC,CACFH,UAAU,EAAI,qFAAqF,CACrG,CAEA;AACA;AACA,KAAM,CAAAK,MAAM,CAAG,0FAA0F,CAEzG;AACA,KAAM,CAAAC,WAAW,CAAG,CAClBrB,QAAQ,CAAE,CACR,CACEC,KAAK,CAAE,CACL,CAAEC,IAAI,CAAEa,UAAW,CAAC,CAExB,CAAC,CACF,CACDO,gBAAgB,CAAE,CAChBC,WAAW,CAAE,GAAG,CAChBC,eAAe,CAAE,GACnB,CACF,CAAC,CAED3C,OAAO,CAACC,GAAG,CAAC,mCAAmC,CAAEsC,MAAM,CAAC,CAExD;AACA,KAAM,CAAA3B,QAAQ,CAAG,KAAM,CAAAC,KAAK,CAC1B,GAAG0B,MAAM,QAAQnC,OAAO,EAAE,CAC1B,CACEU,MAAM,CAAE,MAAM,CACdC,OAAO,CAAE,CACP,cAAc,CAAE,kBAClB,CAAC,CACDC,IAAI,CAAEC,IAAI,CAACC,SAAS,CAACsB,WAAW,CAClC,CACF,CAAC,CAEDxC,OAAO,CAACC,GAAG,CAAC,sBAAsB,CAAEW,QAAQ,CAACW,MAAM,CAAC,CAEpD,GAAI,CAACX,QAAQ,CAACgB,EAAE,CAAE,CAChB,KAAM,CAAAgB,SAAS,CAAG,KAAM,CAAAhC,QAAQ,CAACS,IAAI,CAAC,CAAC,CACvCrB,OAAO,CAAC6B,KAAK,CAAC,YAAY,CAAEjB,QAAQ,CAACW,MAAM,CAAEqB,SAAS,CAAC,CAEvD,GAAIhC,QAAQ,CAACW,MAAM,GAAK,GAAG,CAAE,CAC3B;AACAvB,OAAO,CAACC,GAAG,CAAC,oDAAoD,CAAC,CACjE,MAAO,MAAM,CAAA4C,sBAAsB,CAACX,UAAU,CAAE9B,OAAO,CAAC,CAC1D,CAAC,IAAM,IAAIQ,QAAQ,CAACW,MAAM,GAAK,GAAG,CAAE,CAClC,KAAM,IAAI,CAAAQ,KAAK,CAAC,iEAAiE,CAAC,CACpF,CAAC,IAAM,IAAInB,QAAQ,CAACW,MAAM,GAAK,GAAG,CAAE,CAClC,KAAM,IAAI,CAAAQ,KAAK,CAAC,8CAA8C,CAAC,CACjE,CAAC,IAAM,CACL,KAAM,IAAI,CAAAA,KAAK,CAAC,cAAcnB,QAAQ,CAACW,MAAM,IAAIqB,SAAS,EAAE,CAAC,CAC/D,CACF,CAEA,KAAM,CAAAE,IAAI,CAAG,KAAM,CAAAlC,QAAQ,CAACc,IAAI,CAAC,CAAC,CAElC;AACA,GAAI,CAAAL,IAAI,CAAG,EAAE,CACb,GAAIyB,IAAI,CAACC,UAAU,EACfD,IAAI,CAACC,UAAU,CAAC7C,MAAM,CAAG,CAAC,EAC1B4C,IAAI,CAACC,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,EAC1BF,IAAI,CAACC,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAAC5B,KAAK,CAAE,CACpCC,IAAI,CAAGyB,IAAI,CAACC,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAAC5B,KAAK,CACpC6B,GAAG,CAACC,IAAI,EAAIA,IAAI,CAAC7B,IAAI,EAAI,EAAE,CAAC,CAC5B8B,IAAI,CAAC,EAAE,CAAC,CACXnD,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAEoB,IAAI,CAACnB,MAAM,CAAC,CAClE,CAAC,IAAM,CACLF,OAAO,CAACoD,IAAI,CAAC,oCAAoC,CAAEnC,IAAI,CAACC,SAAS,CAAC4B,IAAI,CAAE,IAAI,CAAE,CAAC,CAAC,CAAC,CACjF,KAAM,IAAI,CAAAf,KAAK,CAAC,mCAAmC,CAAC,CACtD,CAEA,MAAO,CAAAV,IAAI,CACb,CAAE,MAAOQ,KAAK,CAAE,CACd7B,OAAO,CAAC6B,KAAK,CAAC,2BAA2B,CAAEA,KAAK,CAAC,CACjD,KAAM,CAAAA,KAAK,CACb,CACF,CAAC,CAED;AACA,cAAe,CAAAgB,sBAAsBA,CAACQ,MAAM,CAAEC,MAAM,CAAE,CACpD;AACA,KAAM,CAAAC,MAAM,CAAG,CACb,gBAAgB,CAChB,YAAY,CACZ,mBAAmB,CACpB,CAED,GAAI,CAAAC,SAAS,CAAG,IAAI,CAEpB,IAAK,KAAM,CAAAC,KAAK,GAAI,CAAAF,MAAM,CAAE,CAC1B,GAAI,CACFvD,OAAO,CAACC,GAAG,CAAC,iBAAiBwD,KAAK,EAAE,CAAC,CACrC,KAAM,CAAAC,WAAW,CAAG,2DAA2DD,KAAK,kBAAkB,CAEtG,KAAM,CAAAjB,WAAW,CAAG,CAClBrB,QAAQ,CAAE,CACR,CACEC,KAAK,CAAE,CACL,CAAEC,IAAI,CAAEgC,MAAO,CAAC,CAEpB,CAAC,CACF,CACDZ,gBAAgB,CAAE,CAChBC,WAAW,CAAE,GAAG,CAChBC,eAAe,CAAE,GACnB,CACF,CAAC,CAED,KAAM,CAAA/B,QAAQ,CAAG,KAAM,CAAAC,KAAK,CAC1B,GAAG6C,WAAW,QAAQJ,MAAM,EAAE,CAC9B,CACExC,MAAM,CAAE,MAAM,CACdC,OAAO,CAAE,CACP,cAAc,CAAE,kBAClB,CAAC,CACDC,IAAI,CAAEC,IAAI,CAACC,SAAS,CAACsB,WAAW,CAClC,CACF,CAAC,CAED,GAAI,CAAC5B,QAAQ,CAACgB,EAAE,CAAE,CAChB,KAAM,CAAAgB,SAAS,CAAG,KAAM,CAAAhC,QAAQ,CAACS,IAAI,CAAC,CAAC,CACvCrB,OAAO,CAACC,GAAG,CAAC,SAASwD,KAAK,sBAAsB,CAAE7C,QAAQ,CAACW,MAAM,CAAEqB,SAAS,CAAC,CAC7EY,SAAS,CAAG,GAAI,CAAAzB,KAAK,CAAC,kBAAkB0B,KAAK,KAAK7C,QAAQ,CAACW,MAAM,EAAE,CAAC,CACpE,SAAU;AACZ,CAEA,KAAM,CAAAuB,IAAI,CAAG,KAAM,CAAAlC,QAAQ,CAACc,IAAI,CAAC,CAAC,CAElC,GAAIoB,IAAI,CAACC,UAAU,EACfD,IAAI,CAACC,UAAU,CAAC7C,MAAM,CAAG,CAAC,EAC1B4C,IAAI,CAACC,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,EAC1BF,IAAI,CAACC,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAAC5B,KAAK,CAAE,CACpC,KAAM,CAAAC,IAAI,CAAGyB,IAAI,CAACC,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAAC5B,KAAK,CAC1C6B,GAAG,CAACC,IAAI,EAAIA,IAAI,CAAC7B,IAAI,EAAI,EAAE,CAAC,CAC5B8B,IAAI,CAAC,EAAE,CAAC,CACXnD,OAAO,CAACC,GAAG,CAAC,qCAAqCwD,KAAK,EAAE,CAAC,CACzD,MAAO,CAAApC,IAAI,CACb,CAAC,IAAM,CACLrB,OAAO,CAACoD,IAAI,CAAC,4BAA4BK,KAAK,GAAG,CAAExC,IAAI,CAACC,SAAS,CAAC4B,IAAI,CAAE,IAAI,CAAE,CAAC,CAAC,CAAC,CACjFU,SAAS,CAAG,GAAI,CAAAzB,KAAK,CAAC,sCAAsC0B,KAAK,EAAE,CAAC,CACpE,SAAU;AACZ,CACF,CAAE,MAAO5B,KAAK,CAAE,CACd7B,OAAO,CAAC6B,KAAK,CAAC,oBAAoB4B,KAAK,GAAG,CAAE5B,KAAK,CAAC,CAClD2B,SAAS,CAAG3B,KAAK,CACjB;AACF,CACF,CAEA;AACA,KAAM,CAAA2B,SAAS,EAAI,GAAI,CAAAzB,KAAK,CAAC,4BAA4B,CAAC,CAC5D","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}