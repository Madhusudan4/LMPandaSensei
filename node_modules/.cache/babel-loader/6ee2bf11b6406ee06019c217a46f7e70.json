{"ast":null,"code":"import * as pdfjs from 'pdfjs-dist';\nimport { splitTextIntoChunks } from '../utils/textProcessing';\n\n// Set the worker path for PDF.js\npdfjs.GlobalWorkerOptions.workerSrc = `//cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjs.version}/pdf.worker.js`;\n\n// Function to process a PDF document\nexport async function processDocument(file) {\n  try {\n    const arrayBuffer = await readFileAsArrayBuffer(file);\n    const text = await extractTextFromPDF(arrayBuffer);\n    const chunks = splitTextIntoChunks(text);\n\n    // Store document chunks in localStorage\n    storeDocumentChunks(chunks);\n    return chunks.length;\n  } catch (error) {\n    console.error(\"Error processing document:\", error);\n    throw error;\n  }\n}\n\n// Helper function to read file as ArrayBuffer\nfunction readFileAsArrayBuffer(file) {\n  return new Promise((resolve, reject) => {\n    const reader = new FileReader();\n    reader.onload = () => resolve(reader.result);\n    reader.onerror = reject;\n    reader.readAsArrayBuffer(file);\n  });\n}\n\n// Helper function to extract text from PDF using PDF.js\nasync function extractTextFromPDF(arrayBuffer) {\n  try {\n    const pdf = await pdfjs.getDocument({\n      data: arrayBuffer\n    }).promise;\n    let fullText = '';\n    for (let i = 1; i <= pdf.numPages; i++) {\n      const page = await pdf.getPage(i);\n      const content = await page.getTextContent();\n      const pageText = content.items.map(item => item.str).join(' ');\n      fullText += pageText + '\\n\\n';\n    }\n    return fullText;\n  } catch (error) {\n    console.error(\"Error extracting text from PDF:\", error);\n    throw error;\n  }\n}\n\n// Helper function to store document chunks in localStorage\nfunction storeDocumentChunks(chunks) {\n  // Get existing documents\n  const existingDocsString = localStorage.getItem('logisticsDocs') || '[]';\n  const existingDocs = JSON.parse(existingDocsString);\n\n  // Prepare new document chunks with metadata\n  const newDocs = chunks.map((chunk, index) => ({\n    id: `doc_${Date.now()}_${index}`,\n    content: chunk,\n    metadata: {\n      source: 'uploaded_pdf',\n      timestamp: new Date().toISOString(),\n      chunkIndex: index\n    }\n  }));\n\n  // Combine existing and new docs (cap at 100 docs to prevent localStorage overflow)\n  const allDocs = [...existingDocs, ...newDocs].slice(-100);\n\n  // Store in localStorage\n  localStorage.setItem('logisticsDocs', JSON.stringify(allDocs));\n}","map":{"version":3,"names":["pdfjs","splitTextIntoChunks","GlobalWorkerOptions","workerSrc","version","processDocument","file","arrayBuffer","readFileAsArrayBuffer","text","extractTextFromPDF","chunks","storeDocumentChunks","length","error","console","Promise","resolve","reject","reader","FileReader","onload","result","onerror","readAsArrayBuffer","pdf","getDocument","data","promise","fullText","i","numPages","page","getPage","content","getTextContent","pageText","items","map","item","str","join","existingDocsString","localStorage","getItem","existingDocs","JSON","parse","newDocs","chunk","index","id","Date","now","metadata","source","timestamp","toISOString","chunkIndex","allDocs","slice","setItem","stringify"],"sources":["/Users/madhu.sudhan/Documents/logistics-chatbot/src/services/documentService.js"],"sourcesContent":["import * as pdfjs from 'pdfjs-dist';\nimport { splitTextIntoChunks } from '../utils/textProcessing';\n\n// Set the worker path for PDF.js\npdfjs.GlobalWorkerOptions.workerSrc = `//cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjs.version}/pdf.worker.js`;\n\n// Function to process a PDF document\nexport async function processDocument(file) {\n  try {\n    const arrayBuffer = await readFileAsArrayBuffer(file);\n    const text = await extractTextFromPDF(arrayBuffer);\n    const chunks = splitTextIntoChunks(text);\n    \n    // Store document chunks in localStorage\n    storeDocumentChunks(chunks);\n    \n    return chunks.length;\n  } catch (error) {\n    console.error(\"Error processing document:\", error);\n    throw error;\n  }\n}\n\n// Helper function to read file as ArrayBuffer\nfunction readFileAsArrayBuffer(file) {\n  return new Promise((resolve, reject) => {\n    const reader = new FileReader();\n    reader.onload = () => resolve(reader.result);\n    reader.onerror = reject;\n    reader.readAsArrayBuffer(file);\n  });\n}\n\n// Helper function to extract text from PDF using PDF.js\nasync function extractTextFromPDF(arrayBuffer) {\n  try {\n    const pdf = await pdfjs.getDocument({ data: arrayBuffer }).promise;\n    let fullText = '';\n    \n    for (let i = 1; i <= pdf.numPages; i++) {\n      const page = await pdf.getPage(i);\n      const content = await page.getTextContent();\n      const pageText = content.items.map(item => item.str).join(' ');\n      fullText += pageText + '\\n\\n';\n    }\n    \n    return fullText;\n  } catch (error) {\n    console.error(\"Error extracting text from PDF:\", error);\n    throw error;\n  }\n}\n\n// Helper function to store document chunks in localStorage\nfunction storeDocumentChunks(chunks) {\n  // Get existing documents\n  const existingDocsString = localStorage.getItem('logisticsDocs') || '[]';\n  const existingDocs = JSON.parse(existingDocsString);\n  \n  // Prepare new document chunks with metadata\n  const newDocs = chunks.map((chunk, index) => ({\n    id: `doc_${Date.now()}_${index}`,\n    content: chunk,\n    metadata: {\n      source: 'uploaded_pdf',\n      timestamp: new Date().toISOString(),\n      chunkIndex: index\n    }\n  }));\n  \n  // Combine existing and new docs (cap at 100 docs to prevent localStorage overflow)\n  const allDocs = [...existingDocs, ...newDocs].slice(-100);\n  \n  // Store in localStorage\n  localStorage.setItem('logisticsDocs', JSON.stringify(allDocs));\n}\n"],"mappings":"AAAA,OAAO,KAAKA,KAAK,MAAM,YAAY;AACnC,SAASC,mBAAmB,QAAQ,yBAAyB;;AAE7D;AACAD,KAAK,CAACE,mBAAmB,CAACC,SAAS,GAAG,2CAA2CH,KAAK,CAACI,OAAO,gBAAgB;;AAE9G;AACA,OAAO,eAAeC,eAAeA,CAACC,IAAI,EAAE;EAC1C,IAAI;IACF,MAAMC,WAAW,GAAG,MAAMC,qBAAqB,CAACF,IAAI,CAAC;IACrD,MAAMG,IAAI,GAAG,MAAMC,kBAAkB,CAACH,WAAW,CAAC;IAClD,MAAMI,MAAM,GAAGV,mBAAmB,CAACQ,IAAI,CAAC;;IAExC;IACAG,mBAAmB,CAACD,MAAM,CAAC;IAE3B,OAAOA,MAAM,CAACE,MAAM;EACtB,CAAC,CAAC,OAAOC,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,4BAA4B,EAAEA,KAAK,CAAC;IAClD,MAAMA,KAAK;EACb;AACF;;AAEA;AACA,SAASN,qBAAqBA,CAACF,IAAI,EAAE;EACnC,OAAO,IAAIU,OAAO,CAAC,CAACC,OAAO,EAAEC,MAAM,KAAK;IACtC,MAAMC,MAAM,GAAG,IAAIC,UAAU,CAAC,CAAC;IAC/BD,MAAM,CAACE,MAAM,GAAG,MAAMJ,OAAO,CAACE,MAAM,CAACG,MAAM,CAAC;IAC5CH,MAAM,CAACI,OAAO,GAAGL,MAAM;IACvBC,MAAM,CAACK,iBAAiB,CAAClB,IAAI,CAAC;EAChC,CAAC,CAAC;AACJ;;AAEA;AACA,eAAeI,kBAAkBA,CAACH,WAAW,EAAE;EAC7C,IAAI;IACF,MAAMkB,GAAG,GAAG,MAAMzB,KAAK,CAAC0B,WAAW,CAAC;MAAEC,IAAI,EAAEpB;IAAY,CAAC,CAAC,CAACqB,OAAO;IAClE,IAAIC,QAAQ,GAAG,EAAE;IAEjB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,IAAIL,GAAG,CAACM,QAAQ,EAAED,CAAC,EAAE,EAAE;MACtC,MAAME,IAAI,GAAG,MAAMP,GAAG,CAACQ,OAAO,CAACH,CAAC,CAAC;MACjC,MAAMI,OAAO,GAAG,MAAMF,IAAI,CAACG,cAAc,CAAC,CAAC;MAC3C,MAAMC,QAAQ,GAAGF,OAAO,CAACG,KAAK,CAACC,GAAG,CAACC,IAAI,IAAIA,IAAI,CAACC,GAAG,CAAC,CAACC,IAAI,CAAC,GAAG,CAAC;MAC9DZ,QAAQ,IAAIO,QAAQ,GAAG,MAAM;IAC/B;IAEA,OAAOP,QAAQ;EACjB,CAAC,CAAC,OAAOf,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,iCAAiC,EAAEA,KAAK,CAAC;IACvD,MAAMA,KAAK;EACb;AACF;;AAEA;AACA,SAASF,mBAAmBA,CAACD,MAAM,EAAE;EACnC;EACA,MAAM+B,kBAAkB,GAAGC,YAAY,CAACC,OAAO,CAAC,eAAe,CAAC,IAAI,IAAI;EACxE,MAAMC,YAAY,GAAGC,IAAI,CAACC,KAAK,CAACL,kBAAkB,CAAC;;EAEnD;EACA,MAAMM,OAAO,GAAGrC,MAAM,CAAC2B,GAAG,CAAC,CAACW,KAAK,EAAEC,KAAK,MAAM;IAC5CC,EAAE,EAAE,OAAOC,IAAI,CAACC,GAAG,CAAC,CAAC,IAAIH,KAAK,EAAE;IAChChB,OAAO,EAAEe,KAAK;IACdK,QAAQ,EAAE;MACRC,MAAM,EAAE,cAAc;MACtBC,SAAS,EAAE,IAAIJ,IAAI,CAAC,CAAC,CAACK,WAAW,CAAC,CAAC;MACnCC,UAAU,EAAER;IACd;EACF,CAAC,CAAC,CAAC;;EAEH;EACA,MAAMS,OAAO,GAAG,CAAC,GAAGd,YAAY,EAAE,GAAGG,OAAO,CAAC,CAACY,KAAK,CAAC,CAAC,GAAG,CAAC;;EAEzD;EACAjB,YAAY,CAACkB,OAAO,CAAC,eAAe,EAAEf,IAAI,CAACgB,SAAS,CAACH,OAAO,CAAC,CAAC;AAChE","ignoreList":[]},"metadata":{},"sourceType":"module"}