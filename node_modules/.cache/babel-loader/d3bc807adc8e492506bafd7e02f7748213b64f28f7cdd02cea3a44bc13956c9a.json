{"ast":null,"code":"// src/services/aiService.js\nlet documentContext = [];\nexport const setDocumentContext = context => {\n  documentContext = context;\n  console.log(\"Document context updated:\", documentContext.length, \"chunks\");\n};\nexport const queryGeminiAI = async message => {\n  try {\n    const API_KEY = process.env.REACT_APP_GEMINI_API_KEY;\n    if (!API_KEY) {\n      console.error(\"Missing Gemini API key. Set REACT_APP_GEMINI_API_KEY in your environment.\");\n      throw new Error(\"API key not configured\");\n    }\n\n    // Prepare system prompt with specialized knowledge\n    let systemPrompt = \"You are an AI assistant specializing in last mile logistics in India. \";\n    systemPrompt += \"Provide detailed, accurate information about delivery services, tracking, shipping costs, and logistics coverage areas in India. \";\n    systemPrompt += \"Be helpful, concise, and focus on Indian logistics context.\";\n\n    // Add document context if available\n    let contextPrompt = \"\";\n    if (documentContext && documentContext.length > 0) {\n      contextPrompt = \"\\n\\nThe user has uploaded the following document information that you can reference:\\n\";\n      // Only add up to 5 most relevant chunks to avoid token limits\n      const relevantChunks = documentContext.slice(0, 5);\n      relevantChunks.forEach((chunk, i) => {\n        contextPrompt += `\\nDocument Chunk ${i + 1}:\\n${chunk}\\n`;\n      });\n      contextPrompt += \"\\nPlease use this document information when relevant to answer the user's question.\";\n    }\n\n    // Format the request\n    const requestBody = {\n      contents: [{\n        parts: [{\n          text: systemPrompt + contextPrompt\n        }, {\n          text: \"User question: \" + message\n        }]\n      }],\n      generationConfig: {\n        temperature: 0.4,\n        // Lower temperature for more precise responses\n        topK: 40,\n        topP: 0.95,\n        maxOutputTokens: 1024\n      }\n    };\n    console.log(\"Sending request to Gemini API with prompt:\", systemPrompt + contextPrompt);\n\n    // Send the request\n    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\"\n      },\n      body: JSON.stringify(requestBody)\n    });\n    if (!response.ok) {\n      const errorBody = await response.text();\n      console.error(\"API Error:\", response.status, errorBody);\n      throw new Error(`API error: ${response.status} ${errorBody}`);\n    }\n    const data = await response.json();\n\n    // Extract text from the response\n    let text = \"\";\n    if (data.candidates && data.candidates.length > 0 && data.candidates[0].content && data.candidates[0].content.parts) {\n      text = data.candidates[0].content.parts.map(part => part.text || \"\").join(\"\");\n    } else {\n      console.warn(\"Unexpected API response structure:\", data);\n      throw new Error(\"Unexpected API response structure\");\n    }\n    return text;\n  } catch (error) {\n    console.error(\"Error in queryGeminiAI:\", error);\n    throw error;\n  }\n};","map":{"version":3,"names":["documentContext","setDocumentContext","context","console","log","length","queryGeminiAI","message","API_KEY","process","env","REACT_APP_GEMINI_API_KEY","error","Error","systemPrompt","contextPrompt","relevantChunks","slice","forEach","chunk","i","requestBody","contents","parts","text","generationConfig","temperature","topK","topP","maxOutputTokens","response","fetch","method","headers","body","JSON","stringify","ok","errorBody","status","data","json","candidates","content","map","part","join","warn"],"sources":["/Users/madhu.sudhan/Documents/logistics-chatbot/src/services/aiService.js"],"sourcesContent":["// src/services/aiService.js\nlet documentContext = [];\n\nexport const setDocumentContext = (context) => {\n  documentContext = context;\n  console.log(\"Document context updated:\", documentContext.length, \"chunks\");\n};\n\nexport const queryGeminiAI = async (message) => {\n  try {\n    const API_KEY = process.env.REACT_APP_GEMINI_API_KEY;\n    \n    if (!API_KEY) {\n      console.error(\"Missing Gemini API key. Set REACT_APP_GEMINI_API_KEY in your environment.\");\n      throw new Error(\"API key not configured\");\n    }\n\n    // Prepare system prompt with specialized knowledge\n    let systemPrompt = \"You are an AI assistant specializing in last mile logistics in India. \";\n    systemPrompt += \"Provide detailed, accurate information about delivery services, tracking, shipping costs, and logistics coverage areas in India. \";\n    systemPrompt += \"Be helpful, concise, and focus on Indian logistics context.\";\n    \n    // Add document context if available\n    let contextPrompt = \"\";\n    if (documentContext && documentContext.length > 0) {\n      contextPrompt = \"\\n\\nThe user has uploaded the following document information that you can reference:\\n\";\n      // Only add up to 5 most relevant chunks to avoid token limits\n      const relevantChunks = documentContext.slice(0, 5);\n      relevantChunks.forEach((chunk, i) => {\n        contextPrompt += `\\nDocument Chunk ${i+1}:\\n${chunk}\\n`;\n      });\n      contextPrompt += \"\\nPlease use this document information when relevant to answer the user's question.\";\n    }\n\n    // Format the request\n    const requestBody = {\n      contents: [\n        {\n          parts: [\n            { text: systemPrompt + contextPrompt },\n            { text: \"User question: \" + message }\n          ]\n        }\n      ],\n      generationConfig: {\n        temperature: 0.4, // Lower temperature for more precise responses\n        topK: 40,\n        topP: 0.95,\n        maxOutputTokens: 1024\n      }\n    };\n    \n    console.log(\"Sending request to Gemini API with prompt:\", systemPrompt + contextPrompt);\n    \n    // Send the request\n    const response = await fetch(\n      `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`,\n      {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify(requestBody)\n      }\n    );\n\n    if (!response.ok) {\n      const errorBody = await response.text();\n      console.error(\"API Error:\", response.status, errorBody);\n      throw new Error(`API error: ${response.status} ${errorBody}`);\n    }\n\n    const data = await response.json();\n    \n    // Extract text from the response\n    let text = \"\";\n    if (data.candidates && \n        data.candidates.length > 0 && \n        data.candidates[0].content && \n        data.candidates[0].content.parts) {\n      text = data.candidates[0].content.parts\n        .map(part => part.text || \"\")\n        .join(\"\");\n    } else {\n      console.warn(\"Unexpected API response structure:\", data);\n      throw new Error(\"Unexpected API response structure\");\n    }\n    \n    return text;\n  } catch (error) {\n    console.error(\"Error in queryGeminiAI:\", error);\n    throw error;\n  }\n};\n"],"mappings":"AAAA;AACA,IAAIA,eAAe,GAAG,EAAE;AAExB,OAAO,MAAMC,kBAAkB,GAAIC,OAAO,IAAK;EAC7CF,eAAe,GAAGE,OAAO;EACzBC,OAAO,CAACC,GAAG,CAAC,2BAA2B,EAAEJ,eAAe,CAACK,MAAM,EAAE,QAAQ,CAAC;AAC5E,CAAC;AAED,OAAO,MAAMC,aAAa,GAAG,MAAOC,OAAO,IAAK;EAC9C,IAAI;IACF,MAAMC,OAAO,GAAGC,OAAO,CAACC,GAAG,CAACC,wBAAwB;IAEpD,IAAI,CAACH,OAAO,EAAE;MACZL,OAAO,CAACS,KAAK,CAAC,2EAA2E,CAAC;MAC1F,MAAM,IAAIC,KAAK,CAAC,wBAAwB,CAAC;IAC3C;;IAEA;IACA,IAAIC,YAAY,GAAG,wEAAwE;IAC3FA,YAAY,IAAI,mIAAmI;IACnJA,YAAY,IAAI,6DAA6D;;IAE7E;IACA,IAAIC,aAAa,GAAG,EAAE;IACtB,IAAIf,eAAe,IAAIA,eAAe,CAACK,MAAM,GAAG,CAAC,EAAE;MACjDU,aAAa,GAAG,wFAAwF;MACxG;MACA,MAAMC,cAAc,GAAGhB,eAAe,CAACiB,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC;MAClDD,cAAc,CAACE,OAAO,CAAC,CAACC,KAAK,EAAEC,CAAC,KAAK;QACnCL,aAAa,IAAI,oBAAoBK,CAAC,GAAC,CAAC,MAAMD,KAAK,IAAI;MACzD,CAAC,CAAC;MACFJ,aAAa,IAAI,qFAAqF;IACxG;;IAEA;IACA,MAAMM,WAAW,GAAG;MAClBC,QAAQ,EAAE,CACR;QACEC,KAAK,EAAE,CACL;UAAEC,IAAI,EAAEV,YAAY,GAAGC;QAAc,CAAC,EACtC;UAAES,IAAI,EAAE,iBAAiB,GAAGjB;QAAQ,CAAC;MAEzC,CAAC,CACF;MACDkB,gBAAgB,EAAE;QAChBC,WAAW,EAAE,GAAG;QAAE;QAClBC,IAAI,EAAE,EAAE;QACRC,IAAI,EAAE,IAAI;QACVC,eAAe,EAAE;MACnB;IACF,CAAC;IAED1B,OAAO,CAACC,GAAG,CAAC,4CAA4C,EAAEU,YAAY,GAAGC,aAAa,CAAC;;IAEvF;IACA,MAAMe,QAAQ,GAAG,MAAMC,KAAK,CAC1B,0FAA0FvB,OAAO,EAAE,EACnG;MACEwB,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE;MAClB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAACf,WAAW;IAClC,CACF,CAAC;IAED,IAAI,CAACS,QAAQ,CAACO,EAAE,EAAE;MAChB,MAAMC,SAAS,GAAG,MAAMR,QAAQ,CAACN,IAAI,CAAC,CAAC;MACvCrB,OAAO,CAACS,KAAK,CAAC,YAAY,EAAEkB,QAAQ,CAACS,MAAM,EAAED,SAAS,CAAC;MACvD,MAAM,IAAIzB,KAAK,CAAC,cAAciB,QAAQ,CAACS,MAAM,IAAID,SAAS,EAAE,CAAC;IAC/D;IAEA,MAAME,IAAI,GAAG,MAAMV,QAAQ,CAACW,IAAI,CAAC,CAAC;;IAElC;IACA,IAAIjB,IAAI,GAAG,EAAE;IACb,IAAIgB,IAAI,CAACE,UAAU,IACfF,IAAI,CAACE,UAAU,CAACrC,MAAM,GAAG,CAAC,IAC1BmC,IAAI,CAACE,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,IAC1BH,IAAI,CAACE,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAACpB,KAAK,EAAE;MACpCC,IAAI,GAAGgB,IAAI,CAACE,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAACpB,KAAK,CACpCqB,GAAG,CAACC,IAAI,IAAIA,IAAI,CAACrB,IAAI,IAAI,EAAE,CAAC,CAC5BsB,IAAI,CAAC,EAAE,CAAC;IACb,CAAC,MAAM;MACL3C,OAAO,CAAC4C,IAAI,CAAC,oCAAoC,EAAEP,IAAI,CAAC;MACxD,MAAM,IAAI3B,KAAK,CAAC,mCAAmC,CAAC;IACtD;IAEA,OAAOW,IAAI;EACb,CAAC,CAAC,OAAOZ,KAAK,EAAE;IACdT,OAAO,CAACS,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC;IAC/C,MAAMA,KAAK;EACb;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}